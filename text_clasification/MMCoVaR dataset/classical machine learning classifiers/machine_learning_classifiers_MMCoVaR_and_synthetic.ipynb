{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       192\n",
      "           1       0.90      0.95      0.93       327\n",
      "\n",
      "    accuracy                           0.91       519\n",
      "   macro avg       0.91      0.89      0.90       519\n",
      "weighted avg       0.91      0.91      0.90       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  33]\n",
      " [ 16 311]]\n",
      "AUC: 0.9665042048929663\n",
      "\n",
      "Naive Bayes with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28       192\n",
      "           1       0.67      1.00      0.80       327\n",
      "\n",
      "    accuracy                           0.69       519\n",
      "   macro avg       0.84      0.58      0.54       519\n",
      "weighted avg       0.79      0.69      0.61       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 31 161]\n",
      " [  0 327]]\n",
      "AUC: 0.9067278287461774\n",
      "\n",
      "Logistic Regression with Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.61      0.66       192\n",
      "           1       0.79      0.86      0.83       327\n",
      "\n",
      "    accuracy                           0.77       519\n",
      "   macro avg       0.76      0.74      0.75       519\n",
      "weighted avg       0.77      0.77      0.77       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[118  74]\n",
      " [ 45 282]]\n",
      "AUC: 0.8542940876656473\n",
      "\n",
      "Random Forest with Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70       192\n",
      "           1       0.80      0.93      0.86       327\n",
      "\n",
      "    accuracy                           0.81       519\n",
      "   macro avg       0.82      0.77      0.78       519\n",
      "weighted avg       0.82      0.81      0.80       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[116  76]\n",
      " [ 22 305]]\n",
      "AUC: 0.8667096712538227\n",
      "\n",
      "Random Forest with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.62      0.76       192\n",
      "           1       0.82      0.99      0.90       327\n",
      "\n",
      "    accuracy                           0.86       519\n",
      "   macro avg       0.90      0.81      0.83       519\n",
      "weighted avg       0.88      0.86      0.85       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120  72]\n",
      " [  2 325]]\n",
      "AUC: 0.9318218017329256\n",
      "\n",
      "\n",
      "\n",
      " Running analysis with ngrams enabled \n",
      "\n",
      "\n",
      "\n",
      "Logistic Regression with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       192\n",
      "           1       0.90      0.95      0.93       327\n",
      "\n",
      "    accuracy                           0.91       519\n",
      "   macro avg       0.91      0.89      0.90       519\n",
      "weighted avg       0.91      0.91      0.90       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[159  33]\n",
      " [ 16 311]]\n",
      "AUC: 0.9665042048929663\n",
      "\n",
      "Naive Bayes with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.16      0.28       192\n",
      "           1       0.67      1.00      0.80       327\n",
      "\n",
      "    accuracy                           0.69       519\n",
      "   macro avg       0.84      0.58      0.54       519\n",
      "weighted avg       0.79      0.69      0.61       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 31 161]\n",
      " [  0 327]]\n",
      "AUC: 0.9067278287461774\n",
      "\n",
      "Logistic Regression with Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       192\n",
      "           1       0.82      0.87      0.84       327\n",
      "\n",
      "    accuracy                           0.79       519\n",
      "   macro avg       0.78      0.77      0.77       519\n",
      "weighted avg       0.79      0.79      0.79       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[129  63]\n",
      " [ 44 283]]\n",
      "AUC: 0.855743501529052\n",
      "\n",
      "Random Forest with Word2Vec\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69       192\n",
      "           1       0.80      0.91      0.85       327\n",
      "\n",
      "    accuracy                           0.80       519\n",
      "   macro avg       0.80      0.76      0.77       519\n",
      "weighted avg       0.80      0.80      0.79       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[116  76]\n",
      " [ 29 298]]\n",
      "AUC: 0.868780262487258\n",
      "\n",
      "Random Forest with TF-IDF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.62      0.76       192\n",
      "           1       0.82      0.99      0.90       327\n",
      "\n",
      "    accuracy                           0.86       519\n",
      "   macro avg       0.90      0.81      0.83       519\n",
      "weighted avg       0.88      0.86      0.85       519\n",
      "\n",
      "Confusion Matrix:\n",
      " [[120  72]\n",
      " [  2 325]]\n",
      "AUC: 0.9318218017329256\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from machine_learning_classifiers import TextClassifier\n",
    "\n",
    "#____________________________________________________________\n",
    "# Load synthetic data\n",
    "\n",
    "\n",
    "\n",
    "# --- Data Upload and Preparation ---\n",
    "\n",
    "# Load your CSV file (update the path as needed)\n",
    "# Construct path with os library\n",
    "current_dir = os.getcwd()\n",
    "two_steps_back = os.path.dirname(os.path.dirname(current_dir))\n",
    "path = os.path.join(two_steps_back, 'data', 'vaccination_synthetic_articles_combined.csv')\n",
    "\n",
    "df_new = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# Create a DataFrame for changed articles (label 0)\n",
    "df_changed = df_new[['Changed_article']].dropna().copy()\n",
    "df_changed['text'] = df_changed['Changed_article']\n",
    "df_changed['target'] = 0\n",
    "df_changed['synthetic'] = True\n",
    "\n",
    "# Combine the two DataFrames into one\n",
    "df_synthetic_train = df_changed[['text', 'target', 'synthetic']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ____________________________________________________________\n",
    "# Load the MMCoVaR News Dataset\n",
    "\n",
    "path = os.path.join(two_steps_back, 'data', 'MMCoVaR_News_Dataset.csv')\n",
    "df_MMCoVaR = pd.read_csv(path)\n",
    "\n",
    "\n",
    "# Create a DataFrame for original articles with label 1\n",
    "df_MMCoVaR_train = df_MMCoVaR[['body_text', 'reliability']].copy()\n",
    "df_MMCoVaR_train.columns = ['text', 'target']\n",
    "df_MMCoVaR_train['synthetic'] = False\n",
    "\n",
    "\n",
    "df = pd.concat([df_synthetic_train, df_MMCoVaR_train], ignore_index=True, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#____________________________________________________________\n",
    "# --- Running the Machine Learning Pipeline ---\n",
    "\n",
    "# Instantiate the classifier without n-grams, using default parameters\n",
    "classifier = TextClassifier(\n",
    "    df_MMCoVaR_train,\n",
    "    text_column='text',\n",
    "    target_column='target',\n",
    "    use_ngrams=False,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "classifier.run_analysis()\n",
    "\n",
    "# Optionally, run the analysis with n-grams enabled\n",
    "print(\"\\n\\n\\n Running analysis with ngrams enabled \\n\\n\\n\")\n",
    "classifier_ng = TextClassifier(\n",
    "    df_MMCoVaR_train,\n",
    "    text_column='text',\n",
    "    target_column='target',\n",
    "    use_ngrams=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "classifier_ng.run_analysis()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
