{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lukag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lukag\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpairwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Advanced NLP models\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Optionally, if using fuzzy matching\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Sample text database\u001b[39;00m\n\u001b[0;32m     25\u001b[0m text_database \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Eiffel Tower is located in Paris, France.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe moon orbits the Earth every 27.3 days.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClimate change is impacting global weather patterns.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m ]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "# Text processing libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure you have the necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Numerical computing libraries\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Advanced NLP models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Optionally, if using fuzzy matching\n",
    "\n",
    "\n",
    "# Sample text database\n",
    "text_database = [\n",
    "    \"The Eiffel Tower is located in Paris, France.\",\n",
    "    \"The moon orbits the Earth every 27.3 days.\",\n",
    "    \"COVID-19 vaccines are effective in preventing severe illness.\",\n",
    "    \"Python is a popular programming language for data science.\",\n",
    "    \"Climate change is impacting global weather patterns.\"\n",
    "]\n",
    "\n",
    "# Article to check\n",
    "article = \"\"\"\n",
    "The Eiffel Tower, one of the most famous landmarks in the world, stands tall in the city of Paris.\n",
    "Millions of tourists visit this iconic structure every year. Additionally, advancements in vaccines have shown\n",
    "significant effectiveness in reducing severe cases of COVID-19.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the database entries\n",
    "processed_database = [preprocess_text(entry) for entry in text_database]\n",
    "\n",
    "# Preprocess the article\n",
    "processed_article = preprocess_text(article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all texts for vectorization\n",
    "all_texts = processed_database + [processed_article]\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "# Compute cosine similarity between the article and each database entry\n",
    "article_vector = tfidf_matrix[-1]  # The article is the last item\n",
    "database_vectors = tfidf_matrix[:-1]  # All entries except the last\n",
    "\n",
    "# Calculate similarity scores\n",
    "cosine_similarities = cosine_similarity(article_vector, database_vectors).flatten()\n",
    "\n",
    "# Output similarity scores\n",
    "print(\"TF-IDF Cosine Similarity Scores:\")\n",
    "for idx, score in enumerate(cosine_similarities):\n",
    "    print(f\"Entry {idx + 1}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Sentence Transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the texts\n",
    "database_embeddings = model.encode(text_database)\n",
    "article_embedding = model.encode(article)\n",
    "\n",
    "# Compute cosine similarities\n",
    "semantic_similarities = cosine_similarity(\n",
    "    [article_embedding], database_embeddings\n",
    ").flatten()\n",
    "\n",
    "# Output similarity scores\n",
    "print(\"\\nSemantic Similarity Scores:\")\n",
    "for idx, score in enumerate(semantic_similarities):\n",
    "    print(f\"Entry {idx + 1}: {score:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
